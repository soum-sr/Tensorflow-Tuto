{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the deep learning models with a feedback mechanism, or we can say that the output layer is added to the next input and fed back to the same layer. \n",
    " \n",
    "This type of neural networks are helpful in solving the issues of maintaining context for sequential data, like Stock, Music, weather etc. At each iterative step, the model takes an input and the current state of the network, and produces an output and a new state that is again fed to the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"rnn.jpeg\" height=\"450\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent Networks are very sensitive to changes in their parameters. Since the model is complex and deep, the model may face problems like Exploding Gradient or Vanishing Gradient. For an intuition say we have a neural network of 500 layers and we need to pass an value of 1.01 through the network then (1.01)^500 = 144.77, means we have sent 1.01 at one end and got 144.77!!, now that what we call exploding gradient problem. And if we've sent 0.99 then, (0.99)^500 = 0.00657 the value completely diminished, that is vanishing gradient.\n",
    "    \n",
    "To solve these types of problems a new method was proposed, for remembering important data and forgetting usless data, called Long short term memory or LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short-Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSTM are more complex models used for remembering important data for long time, and forgetting useless data for better preservance of context. The LSTM cell function by different logistic gates and those are responsible for maintaing the data. One is for inputting the data, one is for outputting the data and other is to keep or forget the data depending on the need of neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"lstm.png\" height=\"400\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LSTM using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a network having only one LSTM cell. We have to pass 2 elements to LSTM, the previous output and state, (h and c). Therefore we initialize a state vector, state. Here, state is a tuple with 2 elements, each one is of size [1 x 4], onr for passing previous output to next time step and another for passing previous state to next time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'zeros:0' shape=(1, 4) dtype=float32>,\n",
       " <tf.Tensor 'zeros:0' shape=(1, 4) dtype=float32>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_CELL_SIZE = 4 # output dimension\n",
    "\n",
    "lstm_cell = tf.nn.rnn_cell.LSTMCell(LSTM_CELL_SIZE, state_is_tuple = True, name=\"basic_lstm_cell\")\n",
    "state = (tf.zeros([1,LSTM_CELL_SIZE]),) * 2\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for input:\n",
    " \n",
    "here we will take batch size of 1 and sequence length = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3. 1. 2. 3.]]\n"
     ]
    }
   ],
   "source": [
    "input_data = tf.constant([[1,2,3,1,2,3]],dtype=tf.float32)\n",
    "print (sess.run(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the input to the LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMStateTuple(c=array([[-0.4775696 ,  0.6253809 ,  0.28827164,  0.87296957]],\n",
      "      dtype=float32), h=array([[-0.04009858,  0.28063062,  0.07246678,  0.43371633]],\n",
      "      dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"LSTM_sample1\"):\n",
    "    output, state_new = lstm_cell(input_data, state)\n",
    "    \n",
    "sess.run(tf.global_variables_initializer())\n",
    "print (sess.run(state_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04009858  0.28063062  0.07246678  0.43371633]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets build a 2 layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacked LSTM cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_CELL_SIZE_1 = 4 # 4 hidden nodes\n",
    "cell_1 = tf.nn.rnn_cell.LSTMCell(LSTM_CELL_SIZE_1)\n",
    "cells.append(cell_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_CELL_SIZE_2 = 5 # 5 hidden nodes\n",
    "cell_2 = tf.nn.rnn_cell.LSTMCell(LSTM_CELL_SIZE_2)\n",
    "cells.append(cell_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-layer LSTM, it takes multiple single layer LSTM to create a multilayer stacked LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_lstm = tf.contrib.rnn.MultiRNNCell(cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the RNN from stack_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch size x time steps x features\n",
    "data = tf.placeholder(tf.float32, [None, None, input_dimension])\n",
    "output, state = tf.nn.dynamic_rnn(stacked_lstm, data, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say the input sequence length is 3, and the dimensinoality of the inputs is 6. The input should be a Tensor of shape: [batch_size, max_time, dimension] here it is (2,3,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: [batch_size x time_steps x features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [[[1,2,3,4,5,6], [1,2,3,5,6,4],[1,2,1,2,5,6]], [[1,2,3,4,1,2], [1,1,2,2,3,4],[4,5,6,1,2,3]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending the input to network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.033536  ,  0.01661026, -0.05789775, -0.04315641,\n",
       "          0.0637572 ],\n",
       "        [-0.05706692,  0.09019572, -0.10040656, -0.04486463,\n",
       "          0.16141193],\n",
       "        [-0.09696683,  0.1301327 , -0.14138485, -0.07254476,\n",
       "          0.19495438]],\n",
       "\n",
       "       [[-0.05439714, -0.02239576, -0.04589338, -0.06350569,\n",
       "          0.02007721],\n",
       "        [-0.10373282, -0.03095715, -0.09698373, -0.10114256,\n",
       "          0.05825395],\n",
       "        [-0.155613  , -0.0603398 , -0.13643041, -0.14622346,\n",
       "          0.04277685]]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(output, feed_dict={data: input_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the output which is of the shape (2,3,5) == 2 batches, 3 elements in sequence and the dimensionality of output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
